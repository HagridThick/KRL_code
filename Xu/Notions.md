## Notions

#### node2vec论文

- DPS过远--->根据BFS ? 设置depth值,过远就回溯/跳回等.
- BFS只能探索最近的一圈,或者是邻近社群.多次遍历同一个点的sample重复内容很多--->重复达到多少阈值就结合DFS
- 从deepwalk过来相当于是带biased的walk

#### 综合 微观micro\介观\宏观macro相关

- CTransR在TransE预训练之后,对**头实体和尾实体**之间的**关系(边)**进行聚类,对于一个特定的关系r中,它的头和尾相当于都是这个r类别的聚类.
  - 聚类的思想相当于是针对相同类型的边来作为类别
  - 延伸思考是不是能找其他的图中的相似结构\特殊结构
    - 在整体处理(转换成低维向量)前先对特殊结构做出权重或者其他方式的预处理
    - 例如,对度在1-100作为小节点,度在100-2000中节点,2000+大节点?  (例如微博中的普通用户\大V这样)
- **结合图论里面的知识,给知识图谱提供其他信息**
  - [](https://en.wikipedia.org/wiki/Degeneracy_(graph_theory))
  - 比如上面这个k-cores,是不是能用其找核心点
  - 发散思维到了地铁站线路上,有一些交叉点,或者类似客运中心的大站,应该是提供更多信息的

#### KG2E论文

- 不同实体\关系的正例\负例之间的margin相同,忽略了知识图谱中的centainties和uncentainties
- 论文中的例子是,对于"希拉里"这个名字,如果我们知道她的丈夫是克林顿比起知道她是一个美国人,更能知道,哦,这是那个希拉里. 
  - 所以特定的context在判断这个人的任务上,   配偶关系应该有更大的margin
  - 如果边代表的是类别,其中一个测试集好像就10+类别
- ~~能否结合2-hop的信息?(好像和每个都是1-hop总体没什么区别) ,因为node2vec是通过随机游走把节点串联起来,当做句子,然后再作为句子来处理.能不能游走串联,将串联出的后续点作为头节点的额外信息.~~
- 就像上面的特定判断人的时候,"配偶关系"相当于更重要的权重.那么有没有先定义一个社群的概念,类比到生活中就是在下沙这一块地方,年龄属于青年的,判定为学生类的比重就高了.
  - 好像只适用于类别比较少的情况
  - 如果类别太多不太好手动.

#### 其他

共享邻近点:SNN采用一种基于KNN（最近邻）来算相似度的方法来改进DBSCAN。对于每个点，我们在空间内找出离其最近的k个点（称为k近邻点）。两个点之间相似度就是数这两个点共享了多少个k近邻点。如果这两个点没有共享k近邻点或者这两个点都不是对方的k近邻点，那么这两个点相似度就是0。然后我们把DBSCAN里面的距离公式替换成SNN相似度，重新算每个点的邻域和密度，就可以发现不同密度的簇了。SNN的核心就是，把原始的密度计算替换成基于每对点之间共享的邻域的范围，而忽略其真实的密度分布。SNN的缺点就是必须定义最近邻个数k, 而且其性能对k的大小很敏感。



基于密度峰值的算法DP（Clustering by fast search and find of density peaks），也是采用可视化的方法来帮助查找不同密度的簇。其思想为每个簇都有个最大密度点为簇中心，每个簇中心都吸引并连接其周围密度较低的点，且不同的簇中心点都相对较远。为实现这个思想，它首先计算每个点的密度大小（也是数多少点在邻域eps-neigbourhood内），然后再计算每个点到其最近的且比它密度高的点的距离。这样对每个点我们都有两个属性值，一个是其本身密度值，一个是其到比它密度高的最近点的距离值。对这两个属性我们可以生成一个2维图表（决策图），那么在右上角的几个点就可以代表不同的簇的中心了，即密度高且离其他簇中心较远。然后我们可以把其他的点逐步连接到离其最近的且比它密度高的点，直到最后连到某个簇中心点为止。这样所有共享一个簇中心的点都属于一个簇，而离其他点较远且密度很低的点就是异常点了。由于这个方法是基于相对距离和相对密度来连接点的，所以其可以发现不同密度的簇。DP的缺陷就在于每个簇必须有个最大密度点作为簇中心点，如果一个簇的密度分布均与或者一个簇有多个密度高的点，其就会把某些簇分开成几个子簇。另外DP需要用户指定有多少个簇，在实际操作的时候需要不断尝试调整。



密度比估计（Density-ratio estimation）来克服DBSCAN无法发现不同密度簇的缺陷。密度比的核心思想就是对每个点，计算其密度与其邻域密度的比率，然后用密度比计算替换DBSCAN的密度计算来发现核心点Core point，而其他过程和DBSCAN不变。这样一来，每个局部高密度点就会被选出来作为核心点，从而发现不同密度的簇。基于这个思想，我们还可以把原始数据按其密度分布进行标准化（ReScale），即把密度高的区域进行扩张，密度低的区域继续收缩。这样以来，不同密度的簇就可以变成密度相近的簇了，我们再在标准化后的数据上直接跑DBSCAN就搞定了。这种方法需要用户设置邻域范围来计算密度比